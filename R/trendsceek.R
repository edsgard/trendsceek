
#' Extract cells located in regions exceeding random background expression level
#'
#' \code{get_sigcells} extracts an indicator matrix (cells x genes) specifying which cells are located in regions with higher expression than can be expected by chance, given the spatial location of the cells. It takes the output from \code{cellsceek_test} as input.
#'
#' @param cellpeak_stats A list with with cell-peak statistics for each cell and gene as output by \code{cellsceek_test}.
#' 
#' @return An indicator matrix (cells x genes) containing 0's and 1's specifying which cells are located in regions which significantly higher expression.
#'
#' @examples
#' pp = sim_pois(100)
#' low_expr = c(10, 10)
#' high_expr = c(15, 20)
#' pp = add_markdist_streak(pp, low_expr, high_expr)
#' cellpeak_stats = cellsceek_test(pp)
#' cell_ind_mat = get_sigcells(cellpeak_stats)
#' 
#' @export
get_sigcells <- function(cellpeak_stats){
    gene2sigcells_list = lapply(cellpeak_stats, function(j_gene){j_gene_ordered = dplyr::arrange_(j_gene, 'cell'); dplyr::select_(j_gene_ordered, 'sig.bin')})
    sigcells_df = dplyr::bind_cols(gene2sigcells_list)
    colnames(sigcells_df) = names(cellpeak_stats)
    rownames(sigcells_df) = dplyr::arrange_(cellpeak_stats[[1]], 'cell')$cell

    return(sigcells_df)
}

#' Identify cells located in regions exceeding random background expression level
#'
#' \code{cellsceek_test} identifies cells located in regions with higher expression level than expected by random. The spatial distribution is presumed to be fixed and conditioned on that, the test assesses whether cells are in a region with high expression levels. The background expression 2-dimensional null-distribution is generated by random resampling of the mark distribution followed by 2-dimensional kernel density estimate for each resampling.
#'
#' @param pp A point pattern with one or more mark distributions.
#' @param nrand An integer specifying the number of random resamplings of the mark distribution as to create the null-distribution.
#' @param cell_alpha A numeric specifying a signficance level which is used to flag if a cell has significantly higher expression than expected by random for a particular gene or not.
#' @param h A numeric vector of length 2 specifying the bandwidth of the two-dimensional Gaussian kernel (x, y).
#' 
#' @return A list containing statistics for all cells for each gene.
#'
#' @examples
#' pp = sim_pois(100)
#' low_expr = c(10, 10)
#' high_expr = c(15, 20)
#' pp = add_markdist_streak(pp, low_expr, high_expr)
#' cellpeaks = cellsceek_test(pp)
#' 
#' @export
cellsceek_test <- function(pp, nrand = 100, cell_alpha = 0.05, h = NA){

    ##get cell-stats
    cellstats_list = list()
    marx = pp[['marks']]
    if(!is.numeric(marx) || is.matrix(marx)){
        genes = colnames(pp[['marks']])
    }else{
        genes = 'g1'
    }
    
    for(j_gene in genes){
        print(j_gene)
        j_pp = pp_select(pp, j_gene)
        
        ##get cellstats
        cellstats_list[[j_gene]] = cellsceek_jpp(j_pp, nrand = nrand, cell_alpha = cell_alpha, h = h)
    }

    return(cellstats_list)
}

cellsceek_jpp <- function(j_pp, nrand = 1000, cell_alpha = 0.05, h = NA){
###NB: assumes that the marks are log10-transformed
    
    pos_mat = cbind(j_pp[['x']], j_pp[['y']])
    colnames(pos_mat) = c('x', 'y')
    marx = j_pp[['marks']]
    if(is.data.frame(marx) || is.matrix(marx)){
        if(ncol(marx) > 1){
            stop('The marks can only be of of one-dimension (a single gene)')
        }else{
            marx_vec = marx[, 1]
            names(marx_vec) = rownames(marx)
            marx = marx_vec
        }
    }
    
    ##observed kde
    weights = round(10^marx) ##weights: a vector of integers representing frequencies of individual observations.
    if(is.logical(h)){
        obs.dens = sm::sm.density(x = pos_mat, weights = weights, nbins = 0, display = 'none')
    }else{
        obs.dens = sm::sm.density(x = pos_mat, weights = weights, nbins = 0, display = 'none', h = h)
    }
    est.obs = obs.dens$estimate

    ##generate kde null-dist by random sampling of marx (weights)
    eval.points = obs.dens$eval.points
    npoints_x = nrow(eval.points)
    est.rand = array(NA, dim = c(npoints_x, npoints_x, nrand))
    for(jrand in 1:nrand){
        weights.rand = sample(weights)
        if(is.logical(h)){
            rand.dens = sm::sm.density(x = pos_mat, weights = weights.rand, nbins = 0, eval.points = eval.points, display = 'none')
        }else{
            rand.dens = sm::sm.density(x = pos_mat, weights = weights.rand, nbins = 0, eval.points = eval.points, display = 'none', h = h)
        }
        est.rand[, , jrand] = rand.dens$estimate
    }

    ##upper kde null-dist boundary
    upper = apply(est.rand, c(1, 2), stats::quantile, probs = 1 - cell_alpha)

    ##group grid-bins on below or above upper boundary
    dim(est.obs) = c(npoints_x^2, 1)
    dim(upper) = c(npoints_x^2, 1)
    est.df = as.data.frame(cbind(est.obs, upper))
    colnames(est.df) = c('obs', 'upper')
    est.df = dplyr::mutate_(est.df, sig.bin = ~ifelse(obs > upper, 1, 0), bin.id = ~row_number())

    ##assign each cell (pos_mat) to its grid-bin
    bin.id = apply(pos_mat, 1, function(j_pos){
        j.x = which.min(abs(j_pos['x'] - eval.points[, 'xnew'])) ##xgrid
        j.y = which.min(abs(j_pos['y'] - eval.points[, 'ynew'])) ##ygrid
        jbin = j.x + (j.y - 1) * 50
    })
    cell_df = as.data.frame(cbind(pos_mat, marx, bin.id))
    if(is.null(names(marx))){
        names(marx) = paste('p', 1:length(marx), sep = '')
    }
    cell_df = dplyr::bind_cols(cell_df, as.data.frame(names(marx), stringsAsFactors = FALSE))
    colnames(cell_df)[ncol(cell_df)] = 'cell'
    
    ##join cell2gridbin and gridbin2sigbin
    cell_df = dplyr::inner_join(est.df, cell_df, by = 'bin.id')    
    
    return(cell_df)
}


#' Test for the presence of spatial expression patterns
#'
#' \code{trendsceek_test} tests for the presence of spatial expression patterns. The spatial distribution is presumed to be fixed and conditioned on that, the test assesses whether the mark distribution is non-random.
#'
#' @param pp A point pattern with one or more mark distributions.
#' @param nrand An integer specifying the number of random resamplings of the mark distribution as to create the null-distribution.
#' @param ncores An integer specifying the number of cores to be used by BiocParallel
#' @param alpha_env A numeric specifying a Bonferroni-significance level used to create a test-statistic threshold for each radius, an "envelope". Note that this is solely used for plotting purposes.
#' @param alpha_bh A numeric specifying a Benjamini-Hochberg signficance level used to extract significant genes (note that this can also be done for an arbitrary alpha after trendsceek_test has been called, see \code{extract_sig_genes}).
#' @param alpha_nom_early A numeric specifying an early-stopping threshold for the p-value. If the nominal p-value exceeds this value no more permutations are done for that gene.
#' 
#' @return A list containing trendsceek-statistics for every gene.
#'
#' @examples
#' pp = sim_pois(100)
#' low_expr = c(10, 10)
#' high_expr = c(15, 20)
#' pp = add_markdist_hotspot(pp, low_expr, high_expr)
#' trendstat_list = trendsceek_test(pp, nrand = 100, ncores = 1)
#' 
#' @export
trendsceek_test <- function(pp, nrand = 1e4, ncores = 1, alpha_env = 0.1 / ifelse(is.numeric(pp[['marks']]), length(pp[['marks']]), ncol(pp[['marks']])), alpha_bh = 0.05, alpha_nom_early = (alpha_bh * 4) / ifelse(ifelse(is.numeric(pp[['marks']]), length(pp[['marks']]), ncol(pp[['marks']])) >= 500, 10, 1)){
    
    ##init parallelization
    bp_param = BiocParallel::MulticoreParam(workers = ncores)

    ##get rstats
    marx = pp[['marks']]
    if(is.numeric(marx)){
        nfeats = 1
        feats = 1
    }else{
        nfeats = ncol(marx)
        feats = colnames(marx)
    }
    tstat_list = BiocParallel::bplapply(1:nfeats, calc_trendstats, BPPARAM = bp_param, pp = pp, n.rand = nrand, alpha_env = alpha_env, alpha_nom_early = alpha_nom_early)
    names(tstat_list) = feats

    ##get supinum stats
    supstats_list = tstat2supstat(tstat_list)
    supstats_wide = supstats_list2wide(supstats_list)
    
    ##store
    trendstat_list = list(tstat = tstat_list, supstats = supstats_list, supstats_wide = supstats_wide)

    ##get sig genes
    sig_list = extract_sig_genes(trendstat_list, alpha_bh)

    trendstat_list[['sig_genes_list']] = sig_list
    
    return(trendstat_list)
}

trendsceek_test_nonpar <- function(pp, nrand = 1e4, ncores = 1, alpha_env = 0.05 / ifelse(is.numeric(pp[['marks']]), length(pp[['marks']]), ncol(pp[['marks']])), alpha_bh = 0.05){

    ##get rstats
    marx = pp[['marks']]
    if(is.numeric(marx)){
        nfeats = 1
        feats = 1
    }else{
        nfeats = ncol(marx)
        feats = colnames(marx)
    }
    tstat_list = lapply(1:nfeats, calc_trendstats, pp = pp, n.rand = nrand, alpha_env = alpha_env)
    names(tstat_list) = feats

    ##get supinum stats
    supstats_list = tstat2supstat(tstat_list)
    supstats_wide = supstats_list2wide(supstats_list)
    
    ##store
    trendstat_list = list(tstat = tstat_list, supstats = supstats_list, supstats_wide = supstats_wide)

    ##get sig genes
    sig_list = extract_sig_genes(trendstat_list, alpha_bh)

    trendstat_list[['sig_genes_list']] = sig_list
    
    return(trendstat_list)
}

#' Extract significant genes from trendsceek results
#'
#' \code{extract_sig_genes} extracts significant genes from trendsceek results.
#'
#' @param trendstat_list A list containing results generated by calling \code{trendsceek_test}.
#' @param alpha A numeric specifying a Benjamini-Hochberg signficance level used to extract significant genes.
#' 
#' @return A list containing significant genes for each test.
#'
#' @examples
#' pp = sim_pois(100)
#' low_expr = c(10, 10)
#' high_expr = c(15, 20)
#' pp = add_markdist_hotspot(pp, low_expr, high_expr)
#' trendstat_list = trendsceek_test(pp, nrand = 100, ncores = 1)
#' sig_list = extract_sig_genes(trendstat_list, alpha = 0.05)
#' 
#' @export
extract_sig_genes <- function(trendstat_list, alpha = 0.05){

    supstats_list = trendstat_list[['supstats']]

    ##p.BH
    sig.list = lapply(supstats_list, function(j.df){j.df[which(j.df[, 'p.bh'] <= alpha), ]})
        
    ##remove empty
    anysig.test = names(sig.list)[which(unlist(lapply(sig.list, nrow)) > 0)]
    sig.list = sig.list[anysig.test]

    return(sig.list)
}

supstats_list2wide <- function(supstats.list){

    ##list -> wide table
    stats.long = data.table::melt(supstats.list, id.vars = colnames(supstats.list[[1]])) 
    stats.long = stats.long[, -ncol(stats.long)] #test column already present

    if('vargenes.rank' %in% colnames(stats.long)){
        value.vars = setdiff(colnames(stats.long), c('gene', 'vargenes.rank', 'test'))
        stats.wide = as.data.frame(data.table::dcast(data.table::setDT(stats.long), gene + vargenes.rank ~ test, value.var = value.vars))
    }else{
        value.vars = setdiff(colnames(stats.long), c('gene', 'test'))
        stats.wide = as.data.frame(data.table::dcast(data.table::setDT(stats.long), gene ~ test, value.var = value.vars))
    }
    
    ##set rownames
    rownames(stats.wide) = stats.wide[, 'gene']
    
    ##order
    stats.wide = dplyr::arrange_(stats.wide, 'rank_markcorr')

    return(stats.wide)
}

tstat2supstat <- function(tstat_list){
    
    ##rm genes where an error occured    
    pass.genes = names(tstat_list)[which(unlist(lapply(lapply(tstat_list, class), length)) == 1)]
    tstat_list = tstat_list[pass.genes]
    
    ##extreme point (supremum/supinum) stats 
    supstats.names = setdiff(names(tstat_list[[1]][[1]]), 'r.stat')
    supstats.list = lapply(tstat_list, function(jgene_list, sup.stats){lapply(jgene_list, function(jtest_list, sup.stats = sup.stats){jtest_list[sup.stats]}, sup.stats = sup.stats)}, sup.stats = supstats.names)
    supstats.long = reshape2::melt(supstats.list)
    colnames(supstats.long) = c('value', 'sup.stat', 'test', 'gene')

    ##long -> wide wrt sup.stat
    supstats.df = data.table::dcast(supstats.long, gene + test ~ sup.stat, value.var = 'value')

    ##split by test and order genes
    supstats.list = split(supstats.df, supstats.df[, 'test'])
    supstats.list = lapply(supstats.list, function(j.teststat){j.teststat[order(j.teststat[, 'min.pval'], -j.teststat[, 'max.env.rel.dev']), ]})

    ##add adjusted pval
    supstats.list = lapply(supstats.list, function(j.teststat){p.bh = stats::p.adjust(j.teststat[, 'min.pval'], method = 'BH'); j.teststat = cbind(j.teststat, p.bh); return(j.teststat);})        
    supstats.list = lapply(supstats.list, function(j.teststat){p.bo = stats::p.adjust(j.teststat[, 'min.pval'], method = 'bonferroni'); j.teststat = cbind(j.teststat, p.bo); return(j.teststat);})        
    
    ##add rank column
    supstats.list = lapply(supstats.list, function(j.teststat){rank = 1:nrow(j.teststat); j.teststat = cbind(j.teststat, rank); return(j.teststat);})

    ##set rownames
    supstats.list = lapply(supstats.list, function(jtest.list){rownames(jtest.list) = jtest.list[, 'gene']; return(jtest.list);})

    return(supstats.list)
}

calc_trendstats <- function(jfeat_it, pp, n.rand = 1e4, alpha_env = 0.05, alpha_nom_early = (0.05 * 4) / ifelse(ifelse(is.numeric(pp[['marks']]), length(pp[['marks']]), ncol(pp[['marks']])) >= 500, 10, 1), methods = c('Emark', 'markcorr', 'markvario', 'Vmark')){

    print(jfeat_it)
    
    ##subset on a single mark
    marx = pp[['marks']]
    if(!is.numeric(marx)){
        pp[['marks']] = marx[, jfeat_it]
    }

    ##generate null dist by permuting marks
    ##the same null-dist is used for all methods for comparability
    pp.perm.list = gen_null(pp, n.rand)
    ##TBD: Possibly need to use pool.envelope if running into mem-constraints

    ##calc stats
    tstat.list = calc_pp_trendstats(pp, pp.perm.list, alpha_env, alpha_nom_early, methods)

    return(tstat.list)
}

gen_null <- function(pp, n.rand = 2000){
    ##Randomize to create null
    ##List of pps with fixed positions but randomized labels

    perm = TRUE #keep the marginal mark dist the same
    pp.perm.list = lapply(1:n.rand, function(j.it, pp, permute){spatstat::rlabel(pp, permute = permute)}, pp = pp, permute = perm)    
    
    return(pp.perm.list)
}

calc_pp_trendstats <- function(pp, pp.perm.list, alpha_env = 0.05, alpha_nom_early = 0.5, methods = c('Emark', 'markcorr', 'markvario', 'Vmark')){
###Calculate test statistic of obs and null
    
    ##available test stat methods
    fcns = c(spatstat::Emark, spatstat::markcorr, spatstat::markvario, spatstat::Vmark)
    names(fcns) = c('Emark', 'markcorr', 'markvario', 'Vmark')

    ##subset on selected methods
    fcns = fcns[methods]

    ##calc stats for each selected method
    nsim = length(pp.perm.list)    
    tstat.list = list()
    for(j.fcn.name in names(fcns)){
        j.fcn = fcns[[j.fcn.name]]
        
        print(j.fcn.name)        

        tstat.list[[j.fcn.name]] = calc_pp_trendstats_jmethod(pp, pp.perm.list, j.fcn, alpha_env, alpha_nom_early)
    }

    return(tstat.list)
}

calc_pp_trendstats_jmethod <- function(pp, pp.perm.list, j.fcn, alpha_env = 0.05, alpha_nom_early = 0.5){
###Test stats for observed and simulated null data

    nsim = length(pp.perm.list)    

    ##alpha_early = alpha * alpha_earlystop_mult. Increase nsim one order of magnitude at a time, e.g. 10, 100, 1000. 
    nsim_order = floor(log10(nsim))
    nsim_vec = 10^(1:nsim_order)
    if(nsim != nsim_vec[length(nsim_vec)]){
        nsim_vec = c(nsim_vec, nsim)
    }
    
    ##loop over increasing nsim
    n_simsplits = length(nsim_vec)
    local.stats.list = list()
    j_nsim_it = 0
    j_p = 0
    alpha_nom_earlystop = 0.5 ## just used for 10 first permutations
    tstat.list = list()
    while(j_p <= alpha_nom_earlystop && j_nsim_it < n_simsplits){
        j_nsim_it = j_nsim_it + 1
        if(j_nsim_it > 1){
            alpha_nom_earlystop = alpha_nom_early
        }
        
        print(sprintf('Calculations for null subset %i/%i...', j_nsim_it, n_simsplits))
        
        ##select subset from pregenerated null (pp.perm.list)
        ##e.g. 11-100
        if(j_nsim_it == 1){
            jperm_start = 1
        }else{
            jperm_start = nsim_vec[j_nsim_it - 1] + 1
        }            
        jperm_end = nsim_vec[j_nsim_it]
        
        j_pp_perm_list = pp.perm.list[jperm_start:jperm_end]

        ##get local (per radius) test stats for subset
        ##This is the time-consuming step
        j_nsim = length(j_pp_perm_list)
        j_localstats = spatstat::envelope(pp, j.fcn, nsim = j_nsim, simulate = j_pp_perm_list, global = FALSE, nsim2 = 0, savefuns = TRUE, verbose = FALSE)

        ##add test-stats from previous subsets
        local.stats.list = add_subsetstats(local.stats.list, j_localstats, j_nsim_it)
        
        ##get point-wise envelope test-stats and p-value
        j_envstats.df = get_envstats(local.stats.list[['tstat']], local.stats.list[['nullstats']], alpha_env) ##tstat.local.df, nullstats.local.df
        
        ##global envelope p-value (min across all radii)
        j_p = min(j_envstats.df[, 'p'])
    }

    if(j_nsim_it < n_simsplits){
        earlystop = 1
    }else{
        earlystop = 0
    }
    
    ##*##    
    ##store stats in list
    ##*##
    
    ##pointwise stats: for every radius value
    tstat.list[['r.stat']] = cbind(local.stats.list[['tstat']], j_envstats.df)
    
    ##global envelope stats
    tstat.list[['max.env.rel.dev']] = max(j_envstats.df[, 'env.rel.dev'])
    tstat.list[['max.rel.dev']] = max(j_envstats.df[, 'mean.rel.dev'])
    tstat.list[['min.pval']] = j_p
    tstat.list[['earlystop']] = earlystop
    tstat.list[['nsim_stop']] = j_nsim_it
    tstat.list[['nsim_max']] = n_simsplits
    
    return(tstat.list)
}

get_envstats <- function(tstat.df, nullstats.df, alpha_env){
    
    ##test-stat exp value can differ between different radii, therefore look at deviation (distance) from the exp and not the test-stat directly
    null.mean = tstat.df[, 'exp']
    null.devs = apply(nullstats.df, 2, function(j.sim, null.mean){abs(j.sim - null.mean)}, null.mean = null.mean)
    ##TBD: variance is scale-dependent, varying with exp, which one may want to account for
    
    null.sorted = t(apply(null.devs, 1, sort)) #sort every r_i
    null.global = sort(apply(null.sorted, 2, max), decreasing = TRUE) #max of every kth ranked value across all r_i

    ##*###
    ##P-value calculation
    ##*###
    nsim = ncol(nullstats.df)
    obs.dev = abs(tstat.df[, 'obs'] - null.mean)
    hi.rank = unlist(lapply(obs.dev, function(j.r, null.global){length(which(null.global >= j.r))}, null.global = null.global))
    hi.rank = hi.rank + 1
    p = hi.rank / (nsim + 1) ##no need to use lo.rank and take *2 since already accounted for two-sided test by taking absolute values

    ##*###
    ##Global envelope
    ##*###
    ##already a two.sided test since took absolute values above
    kth.nullval = floor((nsim + 1) * alpha_env)
    if(kth.nullval == 0){
        kth.nullval = 1
    }
    max.dev = null.global[kth.nullval]

    ##global dev
    hi.global = null.mean + max.dev
    lo.global = null.mean - max.dev

    ##Relative deviation from envelope
    env.rel.dev = obs.dev / max.dev
    
    ##*###
    ##Effect size
    ##*###
    ##relative deviation from null.mean
    mean.rel.dev = obs.dev / null.mean

    ##Store
    envstats = cbind(obs.dev, lo.global, hi.global, env.rel.dev, mean.rel.dev, p)

    return(envstats)
}

add_subsetstats <- function(local.stats.list, j_localstats, j_nsim_it){
    
    j_nullstats.local.df = localstat2nulldf(j_localstats)            
    
    ##add test-stats from previous subsets
    if(j_nsim_it == 1){
        tstat.local.df = localstat2df(j_localstats)
        nullstats.local.df = j_nullstats.local.df

    }else{
        
        ##add null stats from previous subset
        nullstats.local.df = local.stats.list[['nullstats']]
        nullstats.local.df = cbind(nullstats.local.df, j_nullstats.local.df)

        ##recalculate null-dist based values present in tstat.df, 'r'
        ##and 'obs' are the same regardless of null dist
        tstat.local.df = local.stats.list[['tstat']]
        tstat.local.df[, 'exp'] = apply(nullstats.local.df, 1, mean)
        tstat.local.df[, 'lo.local'] = apply(nullstats.local.df, 1, min)
        tstat.local.df[, 'hi.local'] = apply(nullstats.local.df, 1, max)
    }

    local.stats.list = list(tstat = tstat.local.df, nullstats = nullstats.local.df)

    return(local.stats.list)    
}

localstat2df <- function(tstat){

    ##tstat -> df    
    tstat.df = as.data.frame(tstat)
    cols = colnames(tstat.df)
    cols[which(cols == 'mmean')] = 'exp'
    cols[which(cols == 'lo')] = 'lo.local'
    cols[which(cols == 'hi')] = 'hi.local'
    colnames(tstat.df) = cols

    return(tstat.df)
}

localstat2nulldf <- function(tstat){
###get null stats
    
    nullstats.df = as.data.frame(attr(tstat, 'simfuns'))

    ##exclude radii
    nullstats.df.nor = nullstats.df[, setdiff(colnames(nullstats.df), 'r')]

    return(nullstats.df.nor)
}

